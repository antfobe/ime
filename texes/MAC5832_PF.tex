% --------------------------------------------------------------
% This is all preamble stuff that you don't have to worry about.
% Head down to where it says "Start here"
% --------------------------------------------------------------
 
\documentclass[12pt]{article}
 
\usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb}
\usepackage{fancyhdr}

\usepackage{graphicx}
	\graphicspath{ {images/} }
\usepackage{scrextend}

\newcommand\NoIndent[1]{%
  \par\vbox{\parbox[t]{\linewidth}{#1}}%
}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
 
\newenvironment{theorem}[2][Theorem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{lemma}[2][Lemma]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{exercise}[2][]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{problem}[2][Problem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{question}[2][]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{corollary}[2][Corollary]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}

\newenvironment{solution}{\begin{proof}[Solution]}{\end{proof}}
\pagestyle{fancy}
\setlength{\headheight}{20pt} 
\rhead{Jean Fobe, NºUSP 7630573}
 
\begin{document}
 
% --------------------------------------------------------------
%                         Start here
% --------------------------------------------------------------
 
\title{General Test - MAC 5872}
\thispagestyle{fancy}
\author{
	Introduction to Machine Learning\\\\
    Jean Fobe, NºUSP 7630573
    }

\maketitle

\begin{enumerate}

\item [\textbf{Q1.}] Alternativa \textit{e} - Nenhuma das afirmações é verdadeira. \\
Se fosse afirmado que o $sign(w^{T}_tx_n) \geq y$, teríamos que a atualização seria com \[w^{T}_{t+1}x_n \leq w^{T}_tx_n,\] deixando o peso novo menos `positivo' que o antigo. \\
Em contrapartida, com $sign(w^{T}_tx_n) < y$, a atualização teria como resultado \[w^{T}_{t+1}x_n > w^{T}_tx_n,\] um resultado menos `negativo' que o valor anterior.
     
\item [\textbf{Q2.}] Alternativa \textit{1} - Não há perda na aproximação do ``\textit{pocket}" quando comparado ao perceptron linear, uma vez que o algoritmo do ``\textit{pocket}" adiciona somente um mecanismo para guardar o melhor resultado das atualizações realizadas. Podemos colocar que por essa funcionalidade adicional, as implementações do ``\textit{pocket}" se tornam mais lentas para um caso linear, já que para cada atualização feita  deverá ainda ser comparado o resultado com o valor guardado pelo ``\textit{pocket}".

\item [\textbf{Q3.}] Podemos listar os seguintes itens do que aprendemos no curso sobre aprendizado supervisionado:
	\begin{itemize}
		\item A função (desconhecida) que queremos aproximar ou ``\textit{target function}";
		\item Os dados de treinamento que forneceremos para o nosso algoritmo de aprendizado;
		\item O conjunto de Hipóteses $\mathcal{H}$, como possíveis soluções que ajudam na aproximação pelo aprendizado;
		\item A aproximação retornada pelo algoritmo ou ``\textit{final hypothesis}";
		\item A distribuição de probabilidades, como forma encaixar ou fazer o \textit{fit} dos dados de treinamento em um intervalo de probabilidades, $P$;
		\item Alternativamente, a ``\textit{target function}" como distribuição de probabilidades, ``\textit{target distribution}", levando em consideração possível ruído nos dados.
	\end{itemize}
	Retirados dos slides das aulas 4 e 5 do Mostafa, temos os seguintes diagramas:\\
\includegraphics[scale=.3]{"images/SupervisedLearning-a"}
\includegraphics[scale=.3]{"images/SupervisedLearning-b"}\\
	A primeira imagem a esquerda mostrando os componentes do aprendizado supervisionado tendo como alvo uma função desconhecida e a segunda imagem substituindo essa função por uma distribuição.

\item [\textbf{Q4.}] Respondendo a tia:\\
	\quad $-$ ``Infelizmente 100 dias é uma quantidade muito pequena quando comparada ao total de dias dos últimos 10 anos, em frações teríamos que é $\frac{2}{73}$, aproximadamente $2,7\%$ do total. Posso argumentar que seria possível escolher 100 entre 100 dias que essa estratégia deu certo e a bolsa poderia até ter caído nesses últimos 10 anos.\\
	Fazendo o contrário da estratégia da amiga e escolhendo 100 dias no mesmo intervalo de tempo, poderia também observar sucesso.\\
	Em fim, 100 amostras é um valor muito pequeno para avaliar essa estratégia dentro de 10 anos. Geralmente em aprendizado de máquina, separamos os dados de forma aleatória em $80\%$ para treinamento e $20\%$ para validação. Dessa forma observamos quais estratégias deram mais certo nos $80\%$ e vemos se não cometemos nenhuma `falácia' com a massa de dados restante.\\
	Então não use a estratégia da amiga sem antes procurar os resultados mais a fundo e de forma mais genérica."

\pagebreak

\item [\textbf{Q5.}] Em outras palavras queremos agrupar N pontos de formas diferentes, que é uma questão de combinatória \[\sum_{i=0}^{N}\dbinom{N}{i} = 2^N.\]
Para provar essa igualdade vamos supor $g(N) = \sum_{i=0}^{N}\dbinom{N}{i}$:
	\begin{align}
		\dbinom{N}{N+1} &= \dbinom{N}{-1} = 0\\
		\dbinom{N+1}{i} &= \dbinom{N}{i} + \dbinom{N}{i-1}\\
		g(N + 1) - g(N) &= \sum_{i=0}^{N+1}\dbinom{N+1}{i} - \sum_{i=0}^{N}\dbinom{N}{i}\\
		g(N + 1) - g(N) &= \sum_{i=0}^{N+1} \left( \dbinom{N+1}{i} - \dbinom{N}{i} \right)\\
		g(N + 1) - g(N) &= \sum_{i=0}^{N+1} \dbinom{N}{i-1} = \sum_{i=0}^{N}\dbinom{N}{i}\\
		g(N + 1) - g(N) &= g(N)\\
		g(N + 1) &= 2 \times g(N),\ com\ g(0) = 1\\
		Como\ g(N)\ dobra\ a\ cada\ incremento\ de\ &N\ por\ 1,\ g(N) = \sum_{i=0}^{N}\dbinom{N}{i} = 2^N
	\end{align}
	Como podemos ter um número menor de retas para separar N pontos, temos que $m_{\mathcal{H}}(N) \leq 2^N$.

\item [\textbf{Q6.}] Alternativa \textit{1} -``\textit{Overfitting}" é um termo estatístico usado para descrever uma análise que apresenta resultados muito precisos para apenas uma parte dos valores de um conjunto de dados, sendo essa mesma análise incapaz de se adequar corretamente para os dados restantes.\\
A quarta edição do \textit{Cambridge Dictionary of Statistics} define \textit{overfitted models} da seguinte forma (p. 314):
	\begin{addmargin}[1em]{2em}% 1em left, 2em right
		\textit{``Models that contain more unknown parameters than can be justified by the data."}
	\end{addmargin}
Para termos menor ``\textit{Overfitting}" é importante que tenhamos em mente o que é ruído no conjunto de dados em questão e como diminuímos a influência para a análise final. Entre dados muito e pouco ruidosos, teremos uma análise menos comprometida para o caso de menor ruído.\\
A dimensão VC também tem influência na construção de um modelo. Buscando um modelo que tem uma boa generalização, ou seja menor risco de estar errado, não devemos escolher uma dimensão VC grande, uma vez que isso afetará a flexibilidade da solução, resultando em ``\textit{overfitting}".

\pagebreak

\item [\textbf{Q7.}] Problem 1.11, page 38.
	\begin{addmargin}[1em]{2em}% 1em left, 2em right
		Dos \textit{slides} de aula temos a seguinte formula: \[E_{in} = \frac{\sum( e( h(x) , f(x) ) )}{N}\]
		Quando $h = f,\ e(h,f) = 0$ e quando $h \neq f$, fazemos uso da \textit{risk matrix}.
		\begin{itemize}
			\item[Supermarket:] $h \neq f,\ e(h,f) = \left\{\begin{array}{l}10,\ h = -1\ e\ f = 1\\1,\ h = 1\ e\ f = -1\end{array}\right.$\\
			Aqui queremos minimizar $E_{in}$ para falsos negativos $h = -1\ e\ f = 1$.
			\item[CIA:] $h \neq f,\ e(h,f) = \left\{\begin{array}{l}1,\ h = -1\ e\ f = 1\\1000,\ h = 1\ e\ f = -1\end{array}\right.$\\
			Aqui queremos minimizar $E_{in}$ para falsos positivos $h = 1\ e\ f = -1$.
		\end{itemize}
	\end{addmargin}

\item [\textbf{Q8.}] Problem 1.12, page 38.
	\begin{addmargin}[1em]{2em}
		\begin{itemize}
			\item[a)] Substituindo $h$ por $h_{mean}$ teremos : \[E_{in}(h_{mean}) = \sum_{n=1}^{N}(\frac{\sum_{n=1}^{N}y_n^2}{N^2} - 2 \times \frac{\sum_{n=1}^{N}y_n^2}{N} + y_n^2) = \sum_{n=1}^{N}(\frac{y^2}{N^2} - \frac{2y^2}{N} + y_n^2)\] \[ E_{in}(h_{mean}) = \frac{\sum_{n=1}^{N}y_n^2}{N} - y^2,\]
			o erro (quadrático) médio. 
			\item[b)] Sabendo que o erro absoluto médio (\textit{mean absolute error}) para uma variável real $c$ e uma variável aleatória $X$ é $E(|X - c|)$ e que a mediana é o valor mínimo de $E(|X-c| - X)$, conseguimos fazer um paralelo com o problema em questão, onde $h=|X-c|$ e $y = |X|$. Para N pontos teremos $E_{in}(h_{med}) = \sum_{n+1}^{N}|h_{med} - yn|$.
			\item[c)] Se $y_N$ se torna um \textit{outlier} em $+ \infty$, o estimador $h_{mean}$, sendo a média de todos $y$, aumenta tendendo ao infinito $h_{mean} \rightarrow \infty$ (admitindo aqui que $y$ não tem mais nenhum ponto em infinito). O estimado $y_{med}$, em contrapartida permanece o mesmo se o ponto perturbado era o de maior valor na amostra, ou muda pouco, caso o contrário.
		\end{itemize}
	\end{addmargin}

\pagebreak	

\item [\textbf{Q9.}] Problem 2.2, page 50.
	\begin{addmargin}[1em]{2em}
		\begin{itemize}
			\item[a)] Em (1) temos $\dbinom{N}{1} + \dbinom{N}{0} \geq m_{\mathcal{H}}(N)$.\\
			Como $\dbinom{N}{1} = N$ e $\dbinom{N}{0} = 1$, $\dbinom{N}{1} + \dbinom{N}{0} = N+1$.\\
			Então, $N + 1 \geq m_{\mathcal{H}}(N)$, que é verdadeiro.\\
			Similarmente, em (2), $\dbinom{N}{2} + \dbinom{N}{1} + \dbinom{N}{0} \geq m_{\mathcal{H}}(N)$, isto é,\\ 
			$\frac{N^2}{2} + \frac{N}{2} + 1 \geq m_{\mathcal{H}}(N)$, que também é verdade.\\
			Agora  em (3) não temos um \textit{break point}, já que conseguimos gerar todas as dicotomias por $\mathcal{H}$. Consequentemente,  não temos um majorante para (3).
			\item[b)] Se $2^N \geq m_{\mathcal{H}}(N)$, existe um \textit{break point} para N que será por um polinômio, então respondemos não.
		\end{itemize}
	\end{addmargin}
	
\item [\textbf{Q10.}] Exercise 2.3, page 50.
	\begin{addmargin}[1em]{2em}
		A dimensão VC será 1, 2 e $\infty$, para (i), (ii) e (iii), respectivamente (como visto nos \textit{slides}).
	\end{addmargin}
\item [\textbf{Q11.}] Exercise 2.4, page 52.
	\begin{addmargin}[1em]{2em}
		\begin{itemize}
			\item[a)] Vamos amostrar $d$ amostras em $\mathcal{D}$, obtendo a matriz de linhas formadas pelas amostras: \[D = \begin{bmatrix} 1 & 0 \\ 0 & I_d	\end{bmatrix}, I_d\ uma\ matriz\ de \ identidade\ d \times d\]
			Vamos provar pela identidade que $D$ é irreversível: 
			\begin{align*}
				det \begin{pmatrix} X & Y \\ Z & W	\end{pmatrix} & = det(X) \times \det(W-Z \times X^{-1} \times Y);\\
				det(D) & = det(1) \times det(I_d - 1 \times 0) = 1. 
			\end{align*}
			Para um vetor de pesos \textbf{w} podemos gerar cada dicotomia selecionando o sinal de cada dimensão \textbf{b}, \textbf{b} $ = G\ \times$ \textbf{w}. Então, $d_{VC} \geq d + 1$.
			\item[b)] Amostrando $d + 1$ itens, observamos que $d + 2$ será uma combinação linear desse primeiro itens, já que pegamos todos os itens (como em `\textit{a)}') que podiam ser gerados pelas combinações de 0 ou 1 de $d$ itens. Em outras palavras, não temos mais parâmetros para variar em \textbf{b} e gerar as dicotomias. Então, $d_{VC} \leq d + 1$.
		\end{itemize}
	\end{addmargin}

\item [\textbf{Q12.}] Exercise 2.6, page 60.
	\begin{addmargin}[1em]{2em}
		\begin{itemize}
			\item[a)] Temos o majorante $E_{test} \approx 0.096$, pela inequalidade de \textit{Hoeffding}, nos dados de teste e como o conjunto de hipóteses é finito, podemos também usar a inequalidade de \textit{Hoeffding} para os dados de treino sem apelar para a dimensão VC.\\
			Como $E_{train} = E_{in} \approx 0.115 > E_{test}$, vemos que o majorante nos dados de teste é melhor.
			\item[b)] Como não estamos mudando o nosso conjunto de hipóteses $\mathcal{H}$, também não estamos lidando com \textit{overfitting}. Isso chega a ser bem curioso, pois permite afirmarmos que com apenas um dado de treino temos as melhores generalizações, lembrando que, nesse caso, a  hipótese tem dimensão suficiente para se ajustar aos dados. Colocando isso em uma expressão, com $M = 1$ e uma hipótese unitária $h$: \[E_{out}(h) \leq \sqrt{\frac{ln \left( \frac{2}{\delta} \right)}{2N}} + E_{in}(h)\]
		\end{itemize}
	\end{addmargin}
\item [\textbf{Q13.}] Exercise 3.6, page 92.
	\begin{addmargin}[1em]{2em}
		\begin{itemize}
			\item[a)]
			\item[b)]
		\end{itemize}
	\end{addmargin}
\item [\textbf{Q14.}] Exercise 3.7, page 92.
	\begin{addmargin}[1em]{2em}
		wot
	\end{addmargin}
\item [\textbf{Q15.}] Exercise 4.4, page 129.
	\begin{addmargin}[1em]{2em}
		Sabendo que:
		\begin{align*}
			E_{in}(\mathbf{w}) & = \frac{(\mathbf{w}^TZ^TZ\mathbf{w} - 2 \mathbf{w}^TZ^Ty + y^Ty)}{N}\\
			Para\ \nabla E_{in}(\mathbf{w}) & = 0,\ subtraimos\ \mathbf{w_{lin}}\ de\ \mathbf{w}\ e\ multiplicamos\ y^T\ por\ I\ -\ H\ (hat\ matrix),\\
			E_{in}(\mathbf{w}) & = \frac{((\mathbf{w - w_{lin}})^TZ^TZ(\mathbf{w - w_{lin}}) - 2 \mathbf{w}^TZ^Ty + y^T(I - H)y)}{N}
		\end{align*}
		\begin{itemize}
			\item[a)] Queremos $\nabla E_{in}(\mathbf{w}) = 0$, então, da expressão acima o valor de \textbf{w} que minimiza $E_{in}$ é $\mathbf{w_{lin}}$.
			\item[b)] O menor $E_{in}$ ocorre quando $\mathbf{w_{lin}} = (Z^TZ)^{-1}Z^Ty$.
		\end{itemize}
	\end{addmargin}
\item [\textbf{Q16.}] Problem 4.8, page 156.
	\begin{addmargin}[1em]{2em}
		Uma forma de regularizar a função de custo para evitar \textit{overfitting} é indtroduzir uma gaussiana de media $\mu = 0$ por cima dos pesos, efetivamente mudando a funçaõ de custo da seguinte forma: \[\tilde{E}(\mathbf{w}) = E(\mathbf{w}) + \frac{\lambda \mathbf{w}^2}{2}.\]
		Observe que isso penaliza pesos grandes e limita a liberdade do modelo proporcionalmente ao parâmetro $\lambda$.\\
		Aplicando o gradiente descendente a essa nova função de custo obtemos: \[\mathbf{w}(t+1) \leftarrow (1-2\eta \lambda)\mathbf{w}(t) - \eta \nabla E_{in}(\mathbf{w}(t)),\]
		onde queriamos chegar.
	\end{addmargin}
\item [\textbf{Q17.}] Problem 7.6, page 7-10 eChapter 7.

\item [\textbf{Q18.}] Problem 7.10, page 7-20 eChapter 7.
\end{enumerate}
\end{document}