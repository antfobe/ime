{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes neurais convolucionais - Convolutional Neural Networks (CNN)\n",
    "\n",
    "Como visto em aula, redes convolucionais são modelos que apreendem filtros para transformar imagens em representações vetoriais.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td>\n",
    "<img align=\"middle\"  width='300' heith='100' src='images/arbitrary_padding_no_strides_transposed.gif'>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "(imagem retirada de [Convolution arithmetic](https://github.com/vdumoulin/conv_arithmetic)) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##  Classificação de imagens usando uma CNN\n",
    "\n",
    "Vamos continuar usando o problema de carro autônomo como exemplo de classificação de imagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# notebook feito para a versão 0.4.0 do Pytorch \n",
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from plots import plot9images, plot_confusion_matrix\n",
    "from util import randomize_in_place\n",
    "from DataHolder import DataHolderGentle\n",
    "% matplotlib inline\n",
    "print(\"PyTorch version = {} \".format(torch.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baixando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Essa célula pode demorar de acordo com sua conexão de internet.\n",
    "# Olhe o terminal para mais informações sobre o download\n",
    "if not os.path.exists(\"self_driving_pi_car_data\"):\n",
    "    pro = subprocess.Popen([\"bash\", \"download.sh\"])\n",
    "    pro.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Novamente vamos usar apenas um pedaço dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_X = np.load(\"self_driving_pi_car_data/train_data.npy\")\n",
    "raw_y = np.load(\"self_driving_pi_car_data/train_labels.npy\")\n",
    "randomize_in_place(raw_X, raw_y)\n",
    "valid_X = raw_X[0:1000]\n",
    "valid_y = raw_y[0:1000]\n",
    "test_X = raw_X[1000:2000]\n",
    "test_y = raw_y[1000:2000]\n",
    "train_X = raw_X[2000:]\n",
    "train_y = raw_y[2000:]\n",
    "labels_legend = [\"forward\", \"left\", \"right\"]\n",
    "\n",
    "del raw_X\n",
    "del raw_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma CNN tem como entrada uma imagem como uma matrix, não como um vetor. \n",
    "\n",
    "Vamos alterar o formato dos nossos dados para ficar do modo correto, aqui vamos usar o formato **(canais, altura, largura)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_X = valid_X.reshape((-1, 3, 45, 80))\n",
    "test_X = test_X.reshape((-1, 3, 45, 80))\n",
    "train_X = train_X.reshape((-1, 3, 45, 80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command2int = {\"forward\": 0, \"left\": 1, \"right\": 2}\n",
    "int2command = {i[1]: i[0] for i in command2int.items()}\n",
    "\n",
    "print(\"Informações sobre os dados\\n\")\n",
    "print(\"- Formato dos dados de treinamento = {}\\n\".format(train_X.shape))\n",
    "print(\"- Formato dos dados de validação = {}\\n\".format(valid_X.shape))\n",
    "print(\"- Formato dos dados de teste = {}\\n\".format(test_X.shape))\n",
    "print(\"- Número de classes = {}\\n\".format(3))\n",
    "print(\"- Legenda das classes:  (0 = forward, 1 = left, 2 = right)\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Olhando alguns exemplos: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img9 = train_X[0:9]\n",
    "labels9 = train_y[0:9]\n",
    "labels9 = [int2command[i] for i in labels9]\n",
    "img9 = img9.reshape((9, 45, 80, 3)) \n",
    "img9 = img9[...,::-1]\n",
    "plot9images(img9, labels9, (45, 80, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também podemos olhar como estão as distribuição das classes nos diferentes conjuntos de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Criando a classe de configuração para a CNN\n",
    "\n",
    "Como nos casos anteriores, vamos usar uma classe para guardar todos os hiper parâmetros relacionado a CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNNConfig(object):\n",
    "    \"\"\"\n",
    "    Holds model hyperparams.\n",
    "    :param height: image height\n",
    "    :type heights: int\n",
    "    :param width: image width\n",
    "    :type width: int\n",
    "    :param channels: image channels\n",
    "    :type channels: int\n",
    "    :param architecture: network dense architecture\n",
    "    :type architecture: list of int\n",
    "    :param conv_architecture: convolutional architecture\n",
    "    :type conv_architecture: list of int\n",
    "    :param kernel_sizes: filter sizes\n",
    "    :type kernel_sizes: list of int\n",
    "    :param pool_kernel: pooling filter sizes\n",
    "    :type pool_kernel: list of int\n",
    "    :param batch_size: batch size for training\n",
    "    :type batch_size: int\n",
    "    :param epochs: number of epochs\n",
    "    :type epochs: int\n",
    "    :param save_step: when step % save_step == 0, the model\n",
    "                      parameters are saved.\n",
    "    :type save_step: int\n",
    "    :param learning_rate: learning rate for the optimizer\n",
    "    :type learning_rate: float\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 height=45,\n",
    "                 width=80,\n",
    "                 channels=3,\n",
    "                 classes=3,\n",
    "                 architecture=[100, 3],\n",
    "                 conv_architecture=[12, 16],\n",
    "                 kernel_sizes=None,\n",
    "                 pool_kernel=None,\n",
    "                 save_step=100,\n",
    "                 batch_size=32,\n",
    "                 epochs=1,\n",
    "                 learning_rate=0.0054,\n",
    "                 momentum=0.1):\n",
    "        if kernel_sizes is None:\n",
    "            self.kernel_sizes = [5] * len(conv_architecture)\n",
    "        else:\n",
    "            self.kernel_sizes = kernel_sizes\n",
    "        if pool_kernel is None:\n",
    "            self.pool_kernel = [2] * len(conv_architecture)\n",
    "        else:\n",
    "            pool_kernel = self.pool_kernel\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.channels = channels\n",
    "        self.classes = classes\n",
    "        self.architecture = architecture\n",
    "        self.conv_architecture = conv_architecture\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.save_step = save_step\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        \n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        Get all attributs values.\n",
    "        :return: all hyperparams as a string\n",
    "        :rtype: str\n",
    "        \"\"\"\n",
    "        status = \"height = {}\\n\".format(self.height)\n",
    "        status += \"width = {}\\n\".format(self.width)\n",
    "        status += \"channels = {}\\n\".format(self.channels)\n",
    "        status += \"classes = {}\\n\".format(self.classes)\n",
    "        status += \"architecture = {}\\n\".format(self.architecture)\n",
    "        status += \"conv_architecture = {}\\n\".format(self.conv_architecture)\n",
    "        status += \"kernel_sizes = {}\\n\".format(self.kernel_sizes)\n",
    "        status += \"pool_kernel = {}\\n\".format(self.pool_kernel)\n",
    "        status += \"batch_size = {}\\n\".format(self.batch_size)\n",
    "        status += \"epochs = {}\\n\".format(self.epochs)\n",
    "        status += \"learning_rate = {}\\n\".format(self.learning_rate)\n",
    "        status += \"momentum = {}\\n\".format(self.momentum)\n",
    "        status += \"save_step = {}\\n\".format(self.save_step)\n",
    "        \n",
    "        \n",
    "        return status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cnn_config = CNNConfig()\n",
    "print(\"Os hiper parâmetros da rede convolucional são:\\n\")\n",
    "print(cnn_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos transformar as imagens em tensores e vamos usar a classe `TensorDataset` para guardar os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(torch.Tensor(train_X),\n",
    "                              torch.Tensor(train_y).type(torch.LongTensor))\n",
    "valid_dataset = TensorDataset(torch.Tensor(valid_X),\n",
    "                              torch.Tensor(valid_y).type(torch.LongTensor))\n",
    "test_dataset = TensorDataset(torch.Tensor(test_X),\n",
    "                              torch.Tensor(test_y).type(torch.LongTensor))\n",
    "\n",
    "self_driving_data = DataHolderGentle(cnn_config, train_dataset, valid_dataset, test_dataset) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  **Exercício **\n",
    "\n",
    "Complete a classe `CNN`.\n",
    "\n",
    "Essa classe é uma implementação de uma CNN arbitrária. Assim, por exemplo, se forem passado os hiper parâmetros:\n",
    "\n",
    "- `architecture = [100, 3]`\n",
    "- `conv_architecture = [12, 16]`\n",
    "- `kernel_sizes = [5, 3]`\n",
    "- `pool_kernel = [3, 2]`\n",
    "\n",
    "essa classe precisa definir uma CNN com duas camadas de **convolução** uma com 12 filtros de tamanho (5, 5) e outra com 16 filtros de tamanho (3, 3). Duas camadas de **pooling** (depois das camadas de convolução) com o filtros de tamanho (3, 3) e (2, 2) respectivamente. Uma **camada escondida** com 100 neurônios e a **camada de saída** com tamanho 3.\n",
    "\n",
    "Lembre que vamos definir uma rede convolucional da seguinte forma:\n",
    "\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td>\n",
    "<img align=\"middle\"  width='800' heith='100' src='images/cnn_arch.png'>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "(imagem retirada de [Introduction to Deep Learning: What Are Convolutional Neural Networks?](https://www.mathworks.com/videos/introduction-to-deep-learning-what-are-convolutional-neural-networks--1489512765771.html)) \n",
    "\n",
    "Ou seja, sempre vamos usar o seguinte padrão para a parte de convolução:\n",
    "\n",
    "\n",
    "**camada de convolução - ReLU - camada de pooling**\n",
    "\n",
    "\n",
    "Por isso que os parâmetros - `conv_architecture`, `kernel_sizes` e `pool_kernel` precisam ter sempre o mesmo tamanho.\n",
    " \n",
    "Você deve definir a inicialização dessa classe e completar os métodos `forward` e `predict`. Note que:\n",
    "\n",
    " - o método `forward` deve retornar apenas os *logits*.\n",
    " \n",
    " - o método `predict` deve retornar $\\mathbf{\\hat{y}}$. Ainda estamos num problema de classificação com várias classes, então a saida da rede, $\\mathbf{\\hat{y}}$, é o resultado da função softmax aplicada aos *logits*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional neural network model.\n",
    "    \n",
    "    You may find nn.Conv2d, nn.MaxPool2d and add_module useful here.\n",
    "    \n",
    "    :param config: hyper params configuration\n",
    "    :type config: CNNConfig\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 config):\n",
    "        super(CNN, self).__init__()\n",
    "        # YOUR CODE HERE:\n",
    "        raise NotImplementedError(\"falta completar o método __init__ da classe CNN\")\n",
    "        # END YOUR CODE\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Computes forward pass\n",
    "\n",
    "        :param x: input tensor\n",
    "        :type x: torch.FloatTensor(shape=(batch_size, number_of_features))\n",
    "        :return: logits\n",
    "        :rtype: torch.FloatTensor(shape=[batch_size, number_of_classes])\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE:\n",
    "        raise NotImplementedError(\"falta completar o método forward da classe CNN\")\n",
    "        # END YOUR CODE        \n",
    "        return logits\n",
    "    \n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Computes model's prediction\n",
    "\n",
    "        :param x: input tensor\n",
    "        :type x: torch.FloatTensor(shape=(batch_size, number_of_features))\n",
    "        :return: model's predictions\n",
    "        :rtype: torch.LongTensor(shape=[batch_size])\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE:\n",
    "        raise NotImplementedError(\"falta completar o método predict da classe CNN\")\n",
    "        # END YOUR CODE        \n",
    "        return predictions        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  **Loop de treinamento**\n",
    "\n",
    "Use a mesma função `train_model_img_classification` que voce definiu no notebook passado (pytorch_basico2.ipynb) para treinar o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model_img_classification(model,\n",
    "                                   config,\n",
    "                                   dataholder,\n",
    "                                   model_path,\n",
    "                                   verbose=True):\n",
    "    \"\"\"\n",
    "    Train a model for image classification\n",
    "\n",
    "    :param model: image classification model\n",
    "    :type model: LogisticRegression or DFN\n",
    "    :param config: image classification model\n",
    "    :type config: LogisticRegression or DFN\n",
    "    :param dataholder: data\n",
    "    :type dataholder: DataHolder or DataHolderGentle\n",
    "    :param model_path: path to save model params\n",
    "    :type model_path: str\n",
    "    :param verbose: param to control print\n",
    "    :type verbose: bool\n",
    "    \"\"\"\n",
    "    train_loader = dataholder.train_loader\n",
    "    valid_loader = dataholder.valid_loader\n",
    "\n",
    "    best_valid_loss = float(\"inf\")\n",
    "    # YOUR CODE HERE:\n",
    "    # i) define the loss criteria and the optimizer. \n",
    "    # You may find nn.CrossEntropyLoss and torch.optim.SGD useful here.\n",
    "    raise NotImplementedError(\"falta completar a função train_model_img_classification\")\n",
    "    # criterion =  \n",
    "    # optimizer =\n",
    "    # END YOUR CODE\n",
    "    \n",
    "    train_loss = []\n",
    "    valid_loss = []\n",
    "    for epoch in range(config.epochs):\n",
    "        for step, (images, labels) in enumerate(train_loader):\n",
    "            # YOUR CODE HERE:\n",
    "            # ii) You should zero the model gradients\n",
    "            # and define the loss function for the train data.\n",
    "            raise NotImplementedError(\"falta completar a função train_model_img_classification\")\n",
    "            # loss = \n",
    "            # END YOUR CODE\n",
    "            if step % config.save_step == 0:\n",
    "                # YOUR CODE HERE:\n",
    "                # iii) You should define the loss function for the valid data.\n",
    "                raise NotImplementedError(\"falta completar a função train_model_img_classification\")\n",
    "                # v_loss = \n",
    "                # END YOUR CODE\n",
    "                valid_loss.append(float(v_loss))\n",
    "                train_loss.append(float(loss))\n",
    "                if float(v_loss) < best_valid_loss:\n",
    "                    msg = \"\\ntrain_loss = {:.3f} | valid_loss = {:.3f}\".format(float(loss),float(v_loss))\n",
    "                    torch.save(model.state_dict(), model_path)\n",
    "                    best_valid_loss = float(v_loss)\n",
    "                    if verbose:\n",
    "                        print(msg, end=\"\")\n",
    "            # YOUR CODE HERE:\n",
    "            # iv) You should do the back propagation\n",
    "            # and do the optimization step.\n",
    "            raise NotImplementedError(\"falta completar a função train_model_img_classification\")            \n",
    "            # END YOUR CODE\n",
    "    if verbose:\n",
    "        x = np.arange(1, len(train_loss) + 1, 1)\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(12, 5))\n",
    "        ax.plot(x, train_loss, label='train loss')\n",
    "        ax.plot(x, valid_loss, label='valid loss')\n",
    "        ax.legend()\n",
    "        plt.xlabel('step')\n",
    "        plt.ylabel('loss')\n",
    "        plt.title('Train and valid loss')\n",
    "        plt.grid(True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testes do exercício"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste da saída do método `forward`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = CNN(cnn_config)\n",
    "images, labels = next(iter(self_driving_data.train_loader))\n",
    "images = images / 255\n",
    "out = cnn_model(images)\n",
    "assert out.type() == 'torch.FloatTensor', \"problemas com o tipo da saida do método forward\"\n",
    "assert out.shape == torch.Size([cnn_config.batch_size, cnn_config.classes]), \"problemas com o shape da saida do método forward\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste da saída do método `predict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = cnn_model.predict(images)\n",
    "assert prediction.type() == 'torch.LongTensor', \"problemas com o tipo da saida do método prediction\"\n",
    "assert prediction.shape == torch.Size([cnn_config.batch_size]), \"problemas com o shape da saida do método prediction\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste do treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cnn_config = CNNConfig(epochs=1)\n",
    "my_cnn_model = CNN(my_cnn_config)\n",
    "\n",
    "test_img, test_labels = next(iter(self_driving_data.test_loader))\n",
    "test_img = test_img / 255\n",
    "pred = my_cnn_model.predict(test_img)\n",
    "pred = pred.numpy()\n",
    "accuracy_before = np.sum(pred == test_labels.numpy())/ test_labels.shape[0]\n",
    "\n",
    "train_model_img_classification(my_cnn_model,\n",
    "                               my_cnn_config,\n",
    "                               self_driving_data,\n",
    "                               'cnn.pkl',\n",
    "                               verbose=True)\n",
    "\n",
    "pred = my_cnn_model.predict(test_img)\n",
    "pred = pred.numpy()\n",
    "accuracy_after = np.sum(pred == test_labels.numpy())/ test_labels.shape[0]\n",
    "\n",
    "print(\"antes do treino, acc = {:.2f}\".format(accuracy_before))\n",
    "print(\"depois do treino, acc = {:.2f}\".format(accuracy_after))\n",
    "\n",
    "\n",
    "assert os.path.exists(\"cnn.pkl\"), \"Problemas ao salvar o modelo\"\n",
    "assert accuracy_after > accuracy_before, \"A acurácia depois do treinamento tem que ser maior do que antes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_param_checker(config, model):\n",
    "    \"\"\"\n",
    "    Check if the dfn model's has the right kind of parameters\n",
    "\n",
    "    :param config: model's hyperparamters \n",
    "    :type config: DFNConfig\n",
    "    :param model: neural network \n",
    "    :type model: DFN\n",
    "    \"\"\"\n",
    "    all_params = list(model.parameters())\n",
    "    msg = \"Modelo sem nenhum parâmetro\"\n",
    "    assert all_params != [], msg  \n",
    "    conv_architecture = config.conv_architecture\n",
    "    architecture = config.architecture\n",
    "\n",
    "\n",
    "    count_b = 0\n",
    "    conv_count_b = 0\n",
    "\n",
    "    for params in all_params:\n",
    "        shape = tuple(params.shape)\n",
    "        if len(shape) == 4:\n",
    "            filters = conv_architecture[conv_count_b]\n",
    "            msgF = \"model's param: {} !=  expected: {}\".format(params.shape[0], filters)\n",
    "            assert filters == params.shape[0], msgF\n",
    "\n",
    "            \n",
    "        elif len(shape) == 2:\n",
    "            W_first_dim = architecture[count_b]\n",
    "            msgW = \"model's param: {} !=  expected: {}\".format(params.shape[0], W_first_dim)\n",
    "            assert W_first_dim == params.shape[0], msgW\n",
    "\n",
    "\n",
    "        elif len(shape) == 1:\n",
    "            if conv_count_b < len(conv_architecture):\n",
    "                b_dim = conv_architecture[conv_count_b]\n",
    "                conv_count_b += 1\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                b_dim = architecture[count_b]\n",
    "                count_b += 1\n",
    "            \n",
    "            msgb = \"model's param: {} !=  expected: {}\".format(params.shape[0], b_dim)\n",
    "            assert b_dim == params.shape[0], msgb\n",
    "\n",
    "    print(\"Todos os parâmetros ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste para diferentes arquiteturas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_config1 = CNNConfig(conv_architecture=[32, 16, 12],\n",
    "                         architecture=[400, 300, 200, 100, 50, 10])\n",
    "deep_model1 = CNN(deep_config1)\n",
    "\n",
    "\n",
    "deep_config2 = CNNConfig(conv_architecture=[16, 12, 10],\n",
    "                         architecture=[300, 200, 100, 50, 27])\n",
    "deep_model2 = CNN(deep_config2)\n",
    "\n",
    "\n",
    "deep_config3 = CNNConfig(conv_architecture=[32, 8],\n",
    "                         architecture=[500, 13])\n",
    "deep_model3 = CNN(deep_config3)\n",
    "\n",
    "shallow_config = CNNConfig(conv_architecture=[32, 12, 8],\n",
    "                           architecture=[10])\n",
    "shallow_model = CNN(shallow_config)\n",
    "\n",
    "cnn_param_checker(deep_config1, deep_model1)\n",
    "cnn_param_checker(deep_config2, deep_model2)\n",
    "cnn_param_checker(deep_config3, deep_model3)\n",
    "cnn_param_checker(shallow_config, shallow_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
