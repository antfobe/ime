{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning\n",
    "\n",
    "Vamos usar uma CNN treinada em um dataset para resolver uma outra tarefa que possivelmente não tem uma ligação direta com a tarefa original.\n",
    "\n",
    "\n",
    "## Classificação morfológica de galaxias\n",
    "\n",
    "Outro problema de classificação de imagens é aquele chamado de **classificação morfológica de galaxias**: precisamos distinguir os tipos de galaxia de a cordo com sua aparência visual.\n",
    "Pegamos alguns exemplos de imagens em [EFIGI reference dataset](https://www.aanda.org/articles/aa/pdf/forth/aa16423-10.pdf). Há cinco tipos de galaxia:  **elliptical**, **irregular** , **spiral**, **dwarf** e **lenticular**.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td>\n",
    "<img align=\"middle\"   width='200' heith='100' src='images/elliptical.png'>\n",
    "<img align=\"middle\"   width='200' heith='100' src='images/irregular.png'>\n",
    "<img align=\"middle\"   width='200' heith='100' src='images/spiral.png'>\n",
    "<img align=\"middle\"   width='200' heith='100' src='images/dwarf.png'>\n",
    "<img align=\"middle\"   width='200' heith='100' src='images/lenticular.png'>\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook feito para a versão 0.4.0 do Pytorch \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import subprocess\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from plots import plot9images, plot_confusion_matrix, plot_histogram_from_labels\n",
    "from util import randomize_in_place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baixando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essa célula pode demorar de acordo com sua conexão de internet.\n",
    "# Olhe o terminal para mais informações sobre o download\n",
    "if not os.path.exists(\"efigi_data\"):\n",
    "    pro = subprocess.Popen([\"bash\", \"download_efigi.sh\"])\n",
    "    pro.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos criar funções para aumentar os dados e normalizá-los."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos usar a classe [`ImageFolder`](https://pytorch.org/docs/stable/torchvision/datasets.html#imagefolder) do PyTorch para transformar as imagens em tensores e aplicar todas as manipulações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'efigi_data'\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "train_data = datasets.ImageFolder(train_dir,transform=data_transforms[\"train\"])\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = os.path.join(data_dir, \"test\")\n",
    "test_data = datasets.ImageFolder(test_dir,transform=data_transforms[\"test\"])\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dir = os.path.join(data_dir, \"valid\")\n",
    "valid_data = datasets.ImageFolder(valid_dir,transform=data_transforms[\"val\"])\n",
    "print(valid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que nesse caso, temos **poucos** dados de treinamento, teste e validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=9, shuffle=True, num_workers=4)\n",
    "valid_loader = DataLoader(valid_data, batch_size=9, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_data, batch_size=45, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos definir algumas variáveis globais úteis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataloaders = {\"train\": train_loader, \"val\": valid_loader}\n",
    "dataset_sizes = {\"train\": len(train_data), \"val\": len(valid_data)}\n",
    "\n",
    "class_names = train_data.classes\n",
    "print(class_names)\n",
    "int2label = {k:v for k,v in enumerate(class_names)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos observar algumas imagens do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_image(inp):\n",
    "    out = torchvision.utils.make_grid(inp)\n",
    "    inp = out.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    return inp\n",
    "\n",
    "\n",
    "inputs, classes = next(iter(train_loader))\n",
    "\n",
    "img9 = inputs[0:9]\n",
    "img9 = np.array([transform_image(i) for i in img9])\n",
    "labels9 = classes[0:9].numpy()\n",
    "labels9 = [int2label[i] for i in labels9]\n",
    "img9 = img9.reshape((9, 224, 224, 3))\n",
    "img9 = img9[...,::-1]\n",
    "plot9images(img9, labels9, (224, 224, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para mudar o lerning rate ao longo do treinamento vamos criar uma outra versão do loop de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos baixar uma CNN já treinada chamada **resnet18**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos congelar todos os pesos dessa rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mudamos a última camada dessa rede para se adptar a nossa tarefa de classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 5)\n",
    "model_ft = model_ft.to(device)\n",
    "print(model_ft.fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar o treinamento vamos definir um função de custo, o otimizafor e como vamos fazer o learning rate decair ao longo do treinamento (aqui estamos usando a classe `lr_scheduler.StepLR`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_ft = optim.SGD(model_ft.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos olhar agora o quão bom está o nosso modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, labels = next(iter(test_loader))\n",
    "\n",
    "pred = model_ft(img)\n",
    "softmax = nn.Softmax(dim=1)\n",
    "out = softmax(pred)\n",
    "_, predictions = torch.max(out, 1) \n",
    "predictions = predictions.numpy()\n",
    "\n",
    "plot_confusion_matrix(truth=labels.numpy(),\n",
    "                      predictions=predictions,\n",
    "                      save=False,\n",
    "                      path=\"transfer_learning_confusion_matrix.png\",\n",
    "                      classes=class_names)\n",
    "\n",
    "pred9 = predictions[0:9]\n",
    "pred9 = [int2label[i] for i in pred9] \n",
    "img9 = img[0:9]\n",
    "img9 = np.array([transform_image(i) for i in img9])\n",
    "labels9 = labels[0:9].numpy()\n",
    "labels9 = [int2label[i] for i in labels9]\n",
    "img9 = img9.reshape((9, 224, 224, 3))\n",
    "img9 = img9[...,::-1]\n",
    "plot9images(img9, labels9, (224, 224, 3), pred9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nosso resultado não está ótimo. Mas note que estamos treinando um modelo com poucos dados. Use outras redes já treinadas para obter uma acurácia maior."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
